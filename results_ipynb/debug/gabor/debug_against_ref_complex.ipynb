{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "double check against <https://github.com/leelabcnbc/tang_jcompneuro/blob/master/results_ipynb/debug/gabor_debug/gabor_fitting_debug_complex_one_neuron.ipynb>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tang_jcompneuro.io import load_image_dataset, load_neural_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.85 0.983125 -7.86739094924e-19\n",
      "(9500,) -1.7763568394e-16 2.48689957516e-16\n"
     ]
    }
   ],
   "source": [
    "neuron_to_work_on = 33\n",
    "y = load_neural_dataset('MkA_Shape')[:, neuron_to_work_on:neuron_to_work_on+1]\n",
    "X = load_image_dataset('Shape_9500', trans=True, scale=0.5, subtract_mean=True, legacy_rescale=True)\n",
    "print(X.min(), X.max(), X.mean())\n",
    "X_mean = X.reshape(len(X), -1).mean(axis=1)\n",
    "print(X_mean.shape, X_mean.min(), X_mean.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = (X, y, None, None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get trainer.\n",
    "from tang_jcompneuro.model_fitting_gabor import get_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complex None\n",
      "bad index 0/192\n"
     ]
    }
   ],
   "source": [
    "trainer = get_trainer('complex')\n",
    "results = trainer(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attrs': {'corr_train': 0.45479408},\n",
       " 'corr': 0.45479408,\n",
       " 'model': functools.partial(<function save_model_to_hdf5_group at 0x2b42d4138598>, saved_params={'loc': array([[ 0.00583964],\n",
       "        [-0.0955117 ]], dtype=float32), 'sigma': array([[ 0.19446135],\n",
       "        [ 0.15373458]], dtype=float32), 'orientation': array([ 4.0409441], dtype=float32), 'frequency': array([ 2.22182369], dtype=float32), 'output_a': array([ 0.0057111], dtype=float32), 'output_b': -0.00022449138}),\n",
       " 'y_test_hat': array([[ 0.02630009,  0.02630009,  0.02630009, ...,  0.10959955,\n",
       "          0.10393838,  0.12891151]], dtype=float32)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pretty match what I got before last cell in previous notebook.\n",
    "# difference might be due to CUDA version, PyTorch internal difference, etc.\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert callable(results['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'frequency': array([ 2.22182369], dtype=float32), 'loc': array([[ 0.00583964],\n",
      "       [-0.0955117 ]], dtype=float32), 'orientation': array([ 4.0409441], dtype=float32), 'output_a': array([ 0.0057111], dtype=float32), 'output_b': -0.00022449138, 'sigma': array([[ 0.19446135],\n",
      "       [ 0.15373458]], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "# see if we can save models.\n",
    "import h5py\n",
    "from tempfile import NamedTemporaryFile\n",
    "from tang_jcompneuro.gabor import load_model_from_hdf5_group\n",
    "\n",
    "with NamedTemporaryFile() as f:\n",
    "    with h5py.File(f.name) as f_tmp:\n",
    "        results['model'](f_tmp)\n",
    "        # probably I should not go out of this second with, as that may close f.\n",
    "        # to avoid all these issues, best way would be create a temp dir, rather than a temp file.\n",
    "        # but whatever.\n",
    "        best_params_complex_OUT = load_model_from_hdf5_group(f_tmp)\n",
    "print(best_params_complex_OUT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
