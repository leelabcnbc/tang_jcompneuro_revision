{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make sure that configs in `model_fitting_cnn` are indeed those that we want based on <https://github.com/leelabcnbc/tang_jcompneuro_revision/blob/master/results_ipynb/single_neuron_exploration/cnn_initial_exploration.ipynb>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tang_jcompneuro.model_fitting_cnn import models_to_train, opt_configs_to_explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tang_jcompneuro.cnn_exploration import one_layer_models_to_explore, opt_configs_to_explore as opt_configs_to_explore_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_arch = {\n",
    "    'k9c3_nobn_k6s2max_vanilla': 'b.3',\n",
    "    'k9c6_nobn_k6s2max_vanilla': 'b.6',\n",
    "    'k9c9_nobn_k6s2max_vanilla': 'b.9',\n",
    "    'k9c12_nobn_k6s2max_vanilla': 'b.12',\n",
    "    'k9c15_nobn_k6s2max_vanilla': 'b.15',\n",
    "}\n",
    "\n",
    "set_opt_to_check = {\n",
    "                   '1e-3L2_1e-3L2_adam002_mse', '1e-4L2_1e-3L2_adam002_mse',\n",
    "                    '1e-3L2_1e-3L2_sgd_mse',     '1e-4L2_1e-3L2_sgd_mse'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 66\n",
      "k9c3_nobn_k6s2max_vanilla\n",
      "{'conv': [{'kernel_size': 9, 'out_channel': 3, 'stride': 1, 'bn': False, 'padding': 0, 'pool': {'kernel_size': 6, 'stride': 2, 'padding': 0, 'pool_type': 'max'}}], 'fc': {'factored': False, 'dropout': None}, 'act_fn': 'relu', 'linear_output': True}\n",
      "k9c6_nobn_k6s2max_vanilla\n",
      "{'conv': [{'kernel_size': 9, 'out_channel': 6, 'stride': 1, 'bn': False, 'padding': 0, 'pool': {'kernel_size': 6, 'stride': 2, 'padding': 0, 'pool_type': 'max'}}], 'fc': {'factored': False, 'dropout': None}, 'act_fn': 'relu', 'linear_output': True}\n",
      "k9c9_nobn_k6s2max_vanilla\n",
      "{'conv': [{'kernel_size': 9, 'out_channel': 9, 'stride': 1, 'bn': False, 'padding': 0, 'pool': {'kernel_size': 6, 'stride': 2, 'padding': 0, 'pool_type': 'max'}}], 'fc': {'factored': False, 'dropout': None}, 'act_fn': 'relu', 'linear_output': True}\n",
      "k9c12_nobn_k6s2max_vanilla\n",
      "{'conv': [{'kernel_size': 9, 'out_channel': 12, 'stride': 1, 'bn': False, 'padding': 0, 'pool': {'kernel_size': 6, 'stride': 2, 'padding': 0, 'pool_type': 'max'}}], 'fc': {'factored': False, 'dropout': None}, 'act_fn': 'relu', 'linear_output': True}\n",
      "k9c15_nobn_k6s2max_vanilla\n",
      "{'conv': [{'kernel_size': 9, 'out_channel': 15, 'stride': 1, 'bn': False, 'padding': 0, 'pool': {'kernel_size': 6, 'stride': 2, 'padding': 0, 'pool_type': 'max'}}], 'fc': {'factored': False, 'dropout': None}, 'act_fn': 'relu', 'linear_output': True}\n"
     ]
    }
   ],
   "source": [
    "# check arch\n",
    "def check_arch():\n",
    "    new_arch_dict = models_to_train\n",
    "    old_arch_dict = one_layer_models_to_explore()\n",
    "    print(len(new_arch_dict), len(old_arch_dict))\n",
    "    for old_arch, new_arch in mapping_arch.items():\n",
    "        print(old_arch)\n",
    "        print(old_arch_dict[old_arch])\n",
    "        assert old_arch_dict[old_arch] == new_arch_dict[new_arch]\n",
    "check_arch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 35\n",
      "1e-3L2_1e-3L2_adam002_mse\n",
      "{'conv': [{'l1': 0.0, 'l2': 0.001, 'l1_bias': 0.0, 'l2_bias': 0.0}], 'fc': {'l1': 0.0, 'l2': 0.001, 'l1_bias': 0.0, 'l2_bias': 0.0}, 'loss': 'mse', 'optimizer': {'optimizer_type': 'adam', 'lr': 0.002}}\n",
      "1e-4L2_1e-3L2_sgd_mse\n",
      "{'conv': [{'l1': 0.0, 'l2': 0.0001, 'l1_bias': 0.0, 'l2_bias': 0.0}], 'fc': {'l1': 0.0, 'l2': 0.001, 'l1_bias': 0.0, 'l2_bias': 0.0}, 'loss': 'mse', 'optimizer': {'optimizer_type': 'sgd', 'lr': 0.1, 'momentum': 0.9}}\n",
      "1e-4L2_1e-3L2_adam002_mse\n",
      "{'conv': [{'l1': 0.0, 'l2': 0.0001, 'l1_bias': 0.0, 'l2_bias': 0.0}], 'fc': {'l1': 0.0, 'l2': 0.001, 'l1_bias': 0.0, 'l2_bias': 0.0}, 'loss': 'mse', 'optimizer': {'optimizer_type': 'adam', 'lr': 0.002}}\n",
      "1e-3L2_1e-3L2_sgd_mse\n",
      "{'conv': [{'l1': 0.0, 'l2': 0.001, 'l1_bias': 0.0, 'l2_bias': 0.0}], 'fc': {'l1': 0.0, 'l2': 0.001, 'l1_bias': 0.0, 'l2_bias': 0.0}, 'loss': 'mse', 'optimizer': {'optimizer_type': 'sgd', 'lr': 0.1, 'momentum': 0.9}}\n"
     ]
    }
   ],
   "source": [
    "# check opt\n",
    "def check_opt():\n",
    "    new_opt_dict = opt_configs_to_explore\n",
    "    old_opt_dict = opt_configs_to_explore_old()\n",
    "    print(len(new_opt_dict), len(old_opt_dict))\n",
    "    for opt in set_opt_to_check:\n",
    "        print(opt)\n",
    "        print(old_opt_dict[opt])\n",
    "        assert old_opt_dict[opt] == new_opt_dict[opt]\n",
    "check_opt()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
