{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make sure that I did the implementation correctly and can output loss in the same way as before, against <https://github.com/leelabcnbc/thesis-proposal-yimeng/blob/master/results_ipynb_blocks/population_neuron_fitting/debug/debug_maskcnn_v1_loss_PyTorch_only_rewrite.ipynb>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import Tensor\n",
    "from torch.backends import cudnn\n",
    "cudnn.benchmark = True\n",
    "cudnn.enabled = True\n",
    "from torch.nn import MSELoss\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import os\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maskcnn import cnn_legacy\n",
    "from tang_jcompneuro import cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dir = '/home/yimengzh/data2/thesis-proposal-yimeng/results_ipynb_blocks/population_neuron_fitting/debug/tmp/TF/v1_loss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(os.path.join(load_dir, 'init_weights.pickle'), 'rb') as f_out:\n",
    "    init_data = pickle.load(f_out)\n",
    "    \n",
    "with open(os.path.join(load_dir, 'losses.pickle'), 'rb') as f_out:\n",
    "    stat_all_batches_ref = pickle.load(f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 103)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_all_batches_ref['res_batch'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['imgs_batch', 'res_batch', 'prediction', 'poisson', 'readout_reg', 'total_loss'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_all_batches_ref.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_old = cnn_legacy.MaskCNNV1(n=stat_all_batches_ref['res_batch'].shape[1], init_dict_tf=init_data)\n",
    "model_old = model_old.cuda()\n",
    "model_old = model_old.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maskcnn.cnn_aux import (get_loss, get_maskcnn_v1_arch_config, v1_maskcnn_generator,\n",
    "                             get_maskcnn_v1_opt_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rewritten = cnn.CNN(get_maskcnn_v1_arch_config(factored_constraint='abs'),\n",
    "    # get_maskcnn_v1_arch_config(factored_constraint=None),  # this would fail\n",
    "                          v1_maskcnn_generator(),\n",
    "                  input_size=31, n=stat_all_batches_ref['res_batch'].shape[1], seed=0)\n",
    "model_rewritten = model_rewritten.cuda()\n",
    "model_rewritten = model_rewritten.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv): Sequential(\n",
       "    (conv0): Conv2d(1, 48, kernel_size=(13, 13), stride=(1, 1), bias=False)\n",
       "    (bn0): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True)\n",
       "    (act0): Softplus(beta=1, threshold=20)\n",
       "    (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True)\n",
       "    (act1): Softplus(beta=1, threshold=20)\n",
       "    (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (fc): FactoredLinear2D(\n",
       "    )\n",
       "  )\n",
       "  (final_act): Softplus(beta=1, threshold=20)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rewritten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv.conv0.weight torch.Size([48, 1, 13, 13])\n",
      "conv.bn0.weight torch.Size([48])\n",
      "conv.bn0.bias torch.Size([48])\n",
      "conv.conv1.weight torch.Size([48, 48, 3, 3])\n",
      "conv.bn1.weight torch.Size([48])\n",
      "conv.bn1.bias torch.Size([48])\n",
      "conv.conv2.weight torch.Size([48, 48, 3, 3])\n",
      "conv.bn2.weight torch.Size([48])\n",
      "conv.bn2.bias torch.Size([48])\n",
      "factored_fc_2d.weight_spatial torch.Size([103, 19, 19])\n",
      "factored_fc_2d.weight_feature torch.Size([103, 48])\n",
      "factored_fc_2d.bias torch.Size([103])\n",
      "conv.conv0.weight torch.Size([48, 1, 13, 13])\n",
      "conv.bn0.weight torch.Size([48])\n",
      "conv.bn0.bias torch.Size([48])\n",
      "conv.conv1.weight torch.Size([48, 48, 3, 3])\n",
      "conv.bn1.weight torch.Size([48])\n",
      "conv.bn1.bias torch.Size([48])\n",
      "conv.conv2.weight torch.Size([48, 48, 3, 3])\n",
      "conv.bn2.weight torch.Size([48])\n",
      "conv.bn2.bias torch.Size([48])\n",
      "fc.fc.weight_spatial torch.Size([103, 19, 19])\n",
      "fc.fc.weight_feature torch.Size([103, 48])\n",
      "fc.fc.bias torch.Size([103])\n",
      "conv.conv0.weight\n",
      "conv.bn0.weight\n",
      "conv.bn0.bias\n",
      "conv.conv1.weight\n",
      "conv.bn1.weight\n",
      "conv.bn1.bias\n",
      "conv.conv2.weight\n",
      "conv.bn2.weight\n",
      "conv.bn2.bias\n",
      "fc.fc.weight_spatial\n",
      "fc.fc.weight_feature\n",
      "fc.fc.bias\n"
     ]
    }
   ],
   "source": [
    "def compare_two_models_and_transfer(model1, model2):\n",
    "    \n",
    "    model_1_dict = dict()\n",
    "    for x, y in model1.named_parameters():\n",
    "        print(x, y.size())\n",
    "        model_1_dict[x] = y\n",
    "    model_2_dict = dict()\n",
    "    for x, y in model2.named_parameters():\n",
    "        print(x, y.size())\n",
    "        model_2_dict[x] = y\n",
    "    mapping = {\n",
    "        'fc.fc.weight_spatial': 'factored_fc_2d.weight_spatial',\n",
    "        'fc.fc.weight_feature': 'factored_fc_2d.weight_feature',\n",
    "        'fc.fc.bias': 'factored_fc_2d.bias',\n",
    "    }\n",
    "    \n",
    "    for x, y in model_2_dict.items():\n",
    "        print(x)\n",
    "        y2 = model_1_dict[mapping.get(x, x)]\n",
    "        assert y.size() == y2.size()\n",
    "        y.data[...] = y2.data\n",
    "        \n",
    "    \n",
    "        \n",
    "compare_two_models_and_transfer(model_old, model_rewritten)\n",
    "del model_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction <class 'numpy.ndarray'>\n",
      "prediction 2060\n",
      "group_sparsity <class 'numpy.float32'>\n",
      "group_sparsity 1\n",
      "5.96147\n",
      "smooth_sparsity <class 'numpy.float32'>\n",
      "smooth_sparsity 1\n",
      "14.4936\n",
      "readout_reg <class 'numpy.float32'>\n",
      "readout_reg 1\n",
      "1.86128\n",
      "poisson <class 'numpy.float32'>\n",
      "poisson 1\n",
      "91.4548\n",
      "total_loss <class 'numpy.float32'>\n",
      "total_loss 1\n",
      "113.771\n"
     ]
    }
   ],
   "source": [
    "\n",
    "compute_loss = get_loss(get_maskcnn_v1_opt_config(),model_rewritten, \n",
    "                        return_dict=True)\n",
    "\n",
    "\n",
    "X_batch = stat_all_batches_ref['imgs_batch'].transpose((0,3,1,2))\n",
    "Y_batch = stat_all_batches_ref['res_batch']\n",
    "Y_batch = Variable(Tensor(Y_batch).cuda())\n",
    "Y_this_batch = model_rewritten(Variable(Tensor(X_batch).cuda()))\n",
    "\n",
    "# compute loss.\n",
    "stat_all_batches = {\n",
    "    'prediction': Y_this_batch.data.cpu().numpy(),\n",
    "#     'conv': bn_this_batch,\n",
    "}\n",
    "stat_all_batches.update(compute_loss(Y_this_batch, Y_batch, model_rewritten))\n",
    "for x_, y_ in stat_all_batches.items():\n",
    "    print(x_, type(y_))\n",
    "    print(x_, y_.size)\n",
    "    if y_.size == 1:\n",
    "        print(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction 1.49012e-07 (1.0, 0.0)\n",
      "poisson 91.4548 91.4548 0.0\n",
      "readout_reg 1.86128 1.86128 0.0\n",
      "total_loss 113.771 113.771 0.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def compare_one_case(x1, x2, title=None):\n",
    "    if title is not None:\n",
    "        print(title, end=' ')\n",
    "    assert x1.dtype == x2.dtype == np.float32\n",
    "    assert x1.shape == x2.shape\n",
    "    print(abs(x1-x2).max(), pearsonr(x1.ravel(), x2.ravel()))\n",
    "    assert(norm(x1.ravel()-x2.ravel())/norm(x2.ravel())) < 1e-5\n",
    "    \n",
    "\n",
    "\n",
    "def compare_batches():\n",
    "    x1 = stat_all_batches\n",
    "    x2 = stat_all_batches_ref\n",
    "    Y_x1, Y_x2 = x1['prediction'], x2['prediction']\n",
    "    compare_one_case(Y_x1, Y_x2, 'prediction')\n",
    "#         bn_x1, bn_x2 = x1['conv'], x2['conv']\n",
    "#         compare_one_case(bn_x1, bn_x2, 'conv')\n",
    "\n",
    "    for k in ('poisson', 'readout_reg',\n",
    "              'total_loss'\n",
    "             ):\n",
    "        print(k, x1[k], x2[k], abs(x1[k]-x2[k]))\n",
    "        assert abs(x1[k]-x2[k]) < 1e-5\n",
    "        \n",
    "compare_batches()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
